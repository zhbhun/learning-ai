## 书籍

- [bookcorpus](https://huggingface.co/datasets/bookcorpus) - 小语言模型如 GPT-2 常用的数据集，包括超过 11000 本电子书，主要包括小说和传记。
- [Gutenberg](https://www.gutenberg.org/) - 有 70000 本书，包括小说、散文、戏剧等作品，是目前最大的开源书籍语料库之一。

## 网络

- [CommonCrawl](https://commoncrawl.org/) - 这个是目前最大的开源网络爬虫数据库，不过这个数据包含了大量脏数据，所以目前常用的四个数据库是 C4、CC-Stories、CC-News 和 RealNews。另外还有两个基于 CommonCrawl 提取的新闻语料库 REALNEWS 和 CC-News。
- [openwebtext](https://huggingface.co/datasets/Skylion007/openwebtext) - An open-source replication of the WebText dataset from OpenAI, that was used to train GPT-2.
- Reddit - http://pushshift.io
- Wikipedia

## 代码

- Github
- StackOverflow